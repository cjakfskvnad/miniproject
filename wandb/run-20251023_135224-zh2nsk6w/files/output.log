
Creating environment (sequence length = 10)...
Creating Transformer model...
Creating DQN agent...

Total parameters: 201347
Device: cuda

Starting training for 1000 episodes...
============================================================
Training:   0%|                                                                                | 0/1000 [00:00<?, ?it/s]/workspace/train_dqn.py:277: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /app/pytorch/torch/csrc/utils/tensor_new.cpp:254.)
  state_tensor = torch.tensor([state], dtype=torch.long)

Episode 10/1000
  Avg Reward: 0.60/10
  Avg Accuracy: 6.00%
  Avg Loss: 0.0000
  Epsilon: 0.9511
  Buffer Size: 16
Training:   1%|â–Š                                                                      | 12/1000 [00:11<15:58,  1.03it/s]

Episode 20/1000
  Avg Reward: 1.70/10
  Avg Accuracy: 17.00%
  Avg Loss: 0.0000
  Epsilon: 0.9046
  Buffer Size: 43

Episode 30/1000
  Avg Reward: 0.80/10
  Avg Accuracy: 8.00%
  Avg Loss: 0.0000
  Epsilon: 0.8604
  Buffer Size: 61

Episode 40/1000
  Avg Reward: 0.70/10
  Avg Accuracy: 7.00%
  Avg Loss: 0.0000
  Epsilon: 0.8183
  Buffer Size: 78

Episode 50/1000
  Avg Reward: 1.20/10
  Avg Accuracy: 12.00%
  Avg Loss: 0.0000
  Epsilon: 0.7783
  Buffer Size: 100

Episode 60/1000
  Avg Reward: 0.20/10
  Avg Accuracy: 2.00%
  Avg Loss: 0.0000
  Epsilon: 0.7403
  Buffer Size: 112

Episode 70/1000
  Avg Reward: 1.70/10
  Avg Accuracy: 17.00%
  Avg Loss: 0.0000
  Epsilon: 0.7041
  Buffer Size: 139

Episode 80/1000
  Avg Reward: 1.40/10
  Avg Accuracy: 14.00%
  Avg Loss: 0.0000
  Epsilon: 0.6696
  Buffer Size: 163

Episode 90/1000
  Avg Reward: 0.70/10
  Avg Accuracy: 7.00%
  Avg Loss: 0.0000
  Epsilon: 0.6369
  Buffer Size: 180

Episode 100/1000
  Avg Reward: 0.90/10
  Avg Accuracy: 9.00%
  Avg Loss: 0.0000
  Epsilon: 0.6058
  Buffer Size: 199
Agent saved to checkpoints/agent_episode_100.pt

Episode 110/1000
  Avg Reward: 1.60/10
  Avg Accuracy: 16.00%
  Avg Loss: 0.0000
  Epsilon: 0.5762
  Buffer Size: 225

Episode 120/1000
  Avg Reward: 1.60/10
  Avg Accuracy: 16.00%
  Avg Loss: 0.0000
  Epsilon: 0.5480
  Buffer Size: 251

Episode 130/1000
  Avg Reward: 2.30/10
  Avg Accuracy: 23.00%
  Avg Loss: 0.0000
  Epsilon: 0.5212
  Buffer Size: 283

Episode 140/1000
  Avg Reward: 0.40/10
  Avg Accuracy: 4.00%
  Avg Loss: 0.0000
  Epsilon: 0.4957
  Buffer Size: 297

Episode 150/1000
  Avg Reward: 0.60/10
  Avg Accuracy: 6.00%
  Avg Loss: 0.0000
  Epsilon: 0.4715
  Buffer Size: 313

Episode 160/1000
  Avg Reward: 0.60/10
  Avg Accuracy: 6.00%
  Avg Loss: 0.0000
  Epsilon: 0.4484
  Buffer Size: 329

Episode 170/1000
  Avg Reward: 1.00/10
  Avg Accuracy: 10.00%
  Avg Loss: 0.0000
  Epsilon: 0.4265
  Buffer Size: 349

Episode 180/1000
  Avg Reward: 0.60/10
  Avg Accuracy: 6.00%
  Avg Loss: 0.0000
  Epsilon: 0.4057
  Buffer Size: 365

Episode 190/1000
  Avg Reward: 1.20/10
  Avg Accuracy: 12.00%
  Avg Loss: 0.0000
  Epsilon: 0.3858
  Buffer Size: 387

Episode 200/1000
  Avg Reward: 0.80/10
  Avg Accuracy: 8.00%
  Avg Loss: 0.0000
  Epsilon: 0.3670
  Buffer Size: 405
Agent saved to checkpoints/agent_episode_200.pt

Episode 210/1000
  Avg Reward: 0.80/10
  Avg Accuracy: 8.00%
  Avg Loss: 0.0000
  Epsilon: 0.3490
  Buffer Size: 423

Episode 220/1000
  Avg Reward: 1.00/10
  Avg Accuracy: 10.00%
  Avg Loss: 0.0000
  Epsilon: 0.3320
  Buffer Size: 443

Episode 230/1000
  Avg Reward: 0.80/10
  Avg Accuracy: 8.00%
  Avg Loss: 0.0000
  Epsilon: 0.3157
  Buffer Size: 461

Episode 240/1000
  Avg Reward: 0.90/10
  Avg Accuracy: 9.00%
  Avg Loss: 0.0000
  Epsilon: 0.3003
  Buffer Size: 480

Episode 250/1000
  Avg Reward: 1.30/10
  Avg Accuracy: 13.00%
  Avg Loss: 0.0000
  Epsilon: 0.2856
  Buffer Size: 503

Episode 260/1000
  Avg Reward: 1.30/10
  Avg Accuracy: 13.00%
  Avg Loss: 0.0000
  Epsilon: 0.2716
  Buffer Size: 526

Episode 270/1000
  Avg Reward: 0.70/10
  Avg Accuracy: 7.00%
  Avg Loss: 0.0000
  Epsilon: 0.2584
  Buffer Size: 543

Episode 280/1000
  Avg Reward: 0.90/10
  Avg Accuracy: 9.00%
  Avg Loss: 0.0000
  Epsilon: 0.2457
  Buffer Size: 562

Episode 290/1000
  Avg Reward: 0.40/10
  Avg Accuracy: 4.00%
  Avg Loss: 0.0000
  Epsilon: 0.2337
  Buffer Size: 576

Episode 300/1000
  Avg Reward: 0.30/10
  Avg Accuracy: 3.00%
  Avg Loss: 0.0000
  Epsilon: 0.2223
  Buffer Size: 589
Agent saved to checkpoints/agent_episode_300.pt

Episode 310/1000
  Avg Reward: 1.70/10
  Avg Accuracy: 17.00%
  Avg Loss: 0.0000
  Epsilon: 0.2114
  Buffer Size: 616

Episode 320/1000
  Avg Reward: 1.10/10
  Avg Accuracy: 11.00%
  Avg Loss: 0.0000
  Epsilon: 0.2011
  Buffer Size: 637

Episode 330/1000
  Avg Reward: 0.70/10
  Avg Accuracy: 7.00%
  Avg Loss: 0.0000
  Epsilon: 0.1913
  Buffer Size: 654

Episode 340/1000
  Avg Reward: 0.40/10
  Avg Accuracy: 4.00%
  Avg Loss: 0.0000
  Epsilon: 0.1819
  Buffer Size: 668

Episode 350/1000
  Avg Reward: 0.80/10
  Avg Accuracy: 8.00%
  Avg Loss: 0.0000
  Epsilon: 0.1730
  Buffer Size: 686

Episode 360/1000
  Avg Reward: 1.50/10
  Avg Accuracy: 15.00%
  Avg Loss: 0.0000
  Epsilon: 0.1646
  Buffer Size: 711

Episode 370/1000
  Avg Reward: 0.90/10
  Avg Accuracy: 9.00%
  Avg Loss: 0.0000
  Epsilon: 0.1565
  Buffer Size: 730

Episode 380/1000
  Avg Reward: 0.80/10
  Avg Accuracy: 8.00%
  Avg Loss: 0.0000
  Epsilon: 0.1489
  Buffer Size: 748

Episode 390/1000
  Avg Reward: 1.40/10
  Avg Accuracy: 14.00%
  Avg Loss: 0.0000
  Epsilon: 0.1416
  Buffer Size: 772

Episode 400/1000
  Avg Reward: 1.00/10
  Avg Accuracy: 10.00%
  Avg Loss: 0.0000
  Epsilon: 0.1347
  Buffer Size: 792
Agent saved to checkpoints/agent_episode_400.pt

Episode 410/1000
  Avg Reward: 1.00/10
  Avg Accuracy: 10.00%
  Avg Loss: 0.0000
  Epsilon: 0.1281
  Buffer Size: 812

Episode 420/1000
  Avg Reward: 0.50/10
  Avg Accuracy: 5.00%
  Avg Loss: 0.0000
  Epsilon: 0.1218
  Buffer Size: 827

Episode 430/1000
  Avg Reward: 0.90/10
  Avg Accuracy: 9.00%
  Avg Loss: 0.0000
  Epsilon: 0.1159
  Buffer Size: 846

Episode 440/1000
  Avg Reward: 0.50/10
  Avg Accuracy: 5.00%
  Avg Loss: 0.0000
  Epsilon: 0.1102
  Buffer Size: 861

Episode 450/1000
  Avg Reward: 1.80/10
  Avg Accuracy: 18.00%
  Avg Loss: 0.0000
  Epsilon: 0.1048
  Buffer Size: 889

Episode 460/1000
  Avg Reward: 1.10/10
  Avg Accuracy: 11.00%
  Avg Loss: 0.0000
  Epsilon: 0.0997
  Buffer Size: 910

Episode 470/1000
  Avg Reward: 0.60/10
  Avg Accuracy: 6.00%
  Avg Loss: 0.0000
  Epsilon: 0.0948
  Buffer Size: 926

Episode 480/1000
  Avg Reward: 1.00/10
  Avg Accuracy: 10.00%
  Avg Loss: 0.0000
  Epsilon: 0.0902
  Buffer Size: 946

Episode 490/1000
  Avg Reward: 1.40/10
  Avg Accuracy: 14.00%
  Avg Loss: 0.0000
  Epsilon: 0.0858
  Buffer Size: 970

Episode 500/1000
  Avg Reward: 3.60/10
  Avg Accuracy: 36.00%
  Avg Loss: 0.0000
  Epsilon: 0.0816
  Buffer Size: 1014
Agent saved to checkpoints/agent_episode_500.pt

Episode 510/1000
  Avg Reward: 0.80/10
  Avg Accuracy: 8.00%
  Avg Loss: 0.4142
  Epsilon: 0.0776
  Buffer Size: 1032

Episode 520/1000
  Avg Reward: 1.70/10
  Avg Accuracy: 17.00%
  Avg Loss: 0.8126
  Epsilon: 0.0738
  Buffer Size: 1059

Episode 530/1000
  Avg Reward: 3.10/10
  Avg Accuracy: 31.00%
  Avg Loss: 0.6878
  Epsilon: 0.0702
  Buffer Size: 1100

Episode 540/1000
  Avg Reward: 2.10/10
  Avg Accuracy: 21.00%
  Avg Loss: 0.9327
  Epsilon: 0.0668
  Buffer Size: 1131

Episode 550/1000
  Avg Reward: 3.20/10
  Avg Accuracy: 32.00%
  Avg Loss: 0.9689
  Epsilon: 0.0635
  Buffer Size: 1173

Episode 560/1000
  Avg Reward: 1.60/10
  Avg Accuracy: 16.00%
  Avg Loss: 1.0198
  Epsilon: 0.0604
  Buffer Size: 1199

Episode 570/1000
  Avg Reward: 2.50/10
  Avg Accuracy: 25.00%
  Avg Loss: 0.9338
  Epsilon: 0.0574
  Buffer Size: 1234

Episode 580/1000
  Avg Reward: 3.50/10
  Avg Accuracy: 35.00%
  Avg Loss: 0.8903
  Epsilon: 0.0546
  Buffer Size: 1279

Episode 590/1000
  Avg Reward: 2.30/10
  Avg Accuracy: 23.00%
  Avg Loss: 0.8798
  Epsilon: 0.0520
  Buffer Size: 1312
Traceback (most recent call last):
  File "/workspace/train_dqn.py", line 495, in <module>
    rewards, accuracies, losses = train_dqn(
                                  ^^^^^^^^^^
  File "/workspace/train_dqn.py", line 289, in train_dqn
    loss = agent.train_step()
           ^^^^^^^^^^^^^^^^^^
  File "/workspace/train_dqn.py", line 197, in train_step
    loss.backward()
  File "/usr/local/lib/python3.12/dist-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
